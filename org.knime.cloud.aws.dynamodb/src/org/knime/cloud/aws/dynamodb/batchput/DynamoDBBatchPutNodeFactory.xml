<?xml version="1.0" encoding="UTF-8"?>
<knimeNode icon="./ddbbatchput.png" type="Sink"
    xmlns="http://knime.org/node/v2.8" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://knime.org/node/v2.10 http://knime.org/node/v2.10.xsd">
    <name>Amazon DynamoDB Batch Put</name>
    <shortDescription>
        Puts data onto DynamoDB.
    </shortDescription>

    <fullDescription>
        <intro>
        <p>
        This nodes writes KNIME table rows as items into DynamoDB. The KNIME table's columns
        are the attributes of the written DynamoDB item, which means that the table must contain
        matching columns for the DynamoDB table's hash and range key attributes. If the table does not
        have a range key, only a column with the name and type of the hash key must be present.
        </p>
        <p>
        The command sent to DynamoDB by this node is BatchWriteItem, with a single batch writing
        at most 25 items, so inserting a large amount of data may take a while. The individual
        write operations on item level are atomic, but the operation is not atomic on batch
        or even node execution level. That means if the node fails in-between, some of the items
        may have been written and others not.
        </p>
        <p>
        A single batch can write at most 16 MB of data and a single item can be as large as 400 KB.
        </p>
        <p>
        If DynamoDB throttles the requests due to insufficient
        provisioned capacity units, unprocessed items are included in the next request.
        Additionally this node employs exponential backoff if throttling occurs. Each time a request
        cannot be completed fully, the next request is sent after a waiting time of 2&#94;nRetry * 100 milliseconds.
        Once a request can be executed completely, the retry counter is reset.
        However, if no item can be deleted, the node fails and you have to increase the provisioned write
        capacity units on the table.
        </p>
        More information can be found in the
        <a href="https://docs.aws.amazon.com/de_de/amazondynamodb/latest/APIReference/API_BatchWriteItem.html">DynamoDB documentation</a>.
        </intro>
        <option name="Region">The region the table is in.</option>
        <option name="Table Name">The table to access.</option>
        <option name="Custom Endpoint" optional="true">A custom endpoint if the default AWS endpoint should not be used, e.g. for DynamoDB Local.</option>
        <option name="Batch Size">The number of items to delete in a single batch (max. 25, min. 1).</option>
        <option name="Publish consumed capacity units as flow variable">
        If checked, the total capacity units used by the operation are published as a flow variable named &quot;batchPutConsumedCapacity&quot;.</option>
    </fullDescription>

    <ports>
        <inPort index="0" name="Amazon Credentials">Credentials for an AWS account</inPort>
        <inPort index="1" name="KNIME table">KNIME data table</inPort>
        <outPort index="0" name="Amazon Credentials">Credentials for an AWS account</outPort>
    </ports>
</knimeNode>

